---
title: "fp8 量化的几种姿势"
date: "2025-10-13T12:22:00.000Z"
lastmod: "2025-10-23T13:32:00.000Z"
draft: false
featuredImage: "https://aha.qingy.ing/api?page_id=28b2875f-4bfe-802b-aceb-e6b06e48c058"
series: []
authors:
  - "Hongbo Mo"
tags:
  - "AI"
  - "PyTorch"
categories:
  - "技术"
NOTION_METADATA:
  object: "page"
  id: "28b2875f-4bfe-802b-aceb-e6b06e48c058"
  created_time: "2025-10-13T12:22:00.000Z"
  last_edited_time: "2025-10-23T13:32:00.000Z"
  created_by:
    object: "user"
    id: "1b106df3-cc7b-493e-9afa-a6a7c977ec1b"
  last_edited_by:
    object: "user"
    id: "1b106df3-cc7b-493e-9afa-a6a7c977ec1b"
  cover:
    type: "file"
    file:
      url: "https://prod-files-secure.s3.us-west-2.amazonaws.com/dc681554-1505-4cec-9\
        a8f-844b66d5dcc8/26c13cd4-5fdd-42b4-b999-932c1238eec9/dafosi.jpeg?X-Amz\
        -Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz\
        -Credential=ASIAZI2LB46663RN2LO7%2F20251024%2Fus-west-2%2Fs3%2Faws4_req\
        uest&X-Amz-Date=20251024T012608Z&X-Amz-Expires=3600&X-Amz-Security-Toke\
        n=IQoJb3JpZ2luX2VjEJn%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJIM\
        EYCIQD7BS3hGemMXp9Yv5YdO0hZj5Kgbf8rGLW6HfePZ%2BN7GwIhAPnr0rCg3Xd103JOAN\
        iwjXLD1sm1jxCuZ%2B%2BFRTt6zakQKv8DCFIQABoMNjM3NDIzMTgzODA1IgwuH3GR%2Fxb\
        gThiXy8cq3ANgEwX0qOEpvAPSNZES0NZxK88EVPxCVPP1aMYZDZM5ukCyRIna6BMcVkXm%2\
        BHUIAdmwzk%2BuQgiWpHr7DnzftNYiTXtnFa2yTJUMRQ8DGNb8jxSL52oytstQqCjmaArMk\
        HQ8Ni2vKI9Zxs6yXN14GV5yX44S75kmPcKK6yp4Zf55WUkyinp9hm244vP2dgcmi%2FyrOn\
        7I0vlXQ46gxwmewbBrteF6fnq2ztIfbKfGwXfPlGigrooo13VIgmanjHryeKU88Yf3TqCQM\
        WsuhNF1ghZ%2FWs3f6pY79p1%2BDMHCnyCmYgXK91rg50qCMXp1gAMdML8F2YyLAuzcRX1F\
        GdR8fewvP2RgpwPfT%2B5LMCqXuo9v2HzNT0PDOFGTBZ0XidGJKm%2FvFbPPUq3kJ%2FPGH\
        eD%2B5d3ZzRBM49ObewxaCtCJZ3KxLmK3p2soaMt3EiDnclCEa%2FFHDEwENZIeSVENn%2B\
        u0lkSngjNQlfz77KAQNqHhJ7hJTuQ8phVwxLYrX1RsG58afgdwv66gIxovJcz4Wx4NQAl82\
        gvB8yUW95WaT%2FCNgYBXNtQ7j9of%2Fq%2Fi1a7Po557A8XaeYjMib6QEQb3N4GfQ%2BGp\
        PD4A3JMcZyZ5yY1Fn6gErR80950Y0BU0M8InQzCtn%2BvHBjqkAWq2oZvD66ma2ua4JOhxO\
        oFH1sdnqVggggT5FEUa1ZO7zNvnj6uoaIFR3djltxz9PqjK3CdlS3ePHFNRUEHuxJSVYbca\
        kX5YWg4TmGUEIS1lsvDZP878EtnY6YgZ4LpAH8aGCUaLCEBTljIq2bJbb2kurI%2BNTh%2B\
        xaV8K1l%2B7ybHOUnhbbaYkQD9DhTL%2FU%2B8ZISLAA39xlQuR3EsfFFPp50DVARl1&X-A\
        mz-Signature=4e691b00f6d4e6221f65958fbd44bc5f6f00035830decc9678829f267f\
        8eec8e&X-Amz-SignedHeaders=host&x-amz-checksum-mode=ENABLED&x-id=GetObj\
        ect"
      expiry_time: "2025-10-24T02:26:08.639Z"
  icon: null
  parent:
    type: "database_id"
    database_id: "2742875f-4bfe-8102-8a94-f918ade28f0e"
  archived: false
  in_trash: false
  is_locked: false
  properties:
    series:
      id: "B%3C%3FS"
      type: "multi_select"
      multi_select: []
    draft:
      id: "JiWU"
      type: "checkbox"
      checkbox: false
    authors:
      id: "bK%3B%5B"
      type: "people"
      people:
        - object: "user"
          id: "1b106df3-cc7b-493e-9afa-a6a7c977ec1b"
          name: "Hongbo Mo"
          avatar_url: "https://lh3.googleusercontent.com/-TqDAswHjpLU/AAAAAAAAAAI/AAAAAAA\
            ACcE/ytljzmTe0FE/photo.jpg"
          type: "person"
          person:
            email: "zjutpolym@gmail.com"
    custom-front-matter:
      id: "c~kA"
      type: "rich_text"
      rich_text: []
    tags:
      id: "jw%7CC"
      type: "multi_select"
      multi_select:
        - id: "40547cf7-b44a-442e-bda4-0c8227541945"
          name: "AI"
          color: "purple"
        - id: "683854ba-d6f3-4e29-a95e-585859c16642"
          name: "PyTorch"
          color: "orange"
    categories:
      id: "nbY%3F"
      type: "multi_select"
      multi_select:
        - id: "3e64a788-1d3d-460d-ad3a-18dc5cbc48e5"
          name: "技术"
          color: "brown"
    Last edited time:
      id: "vbGE"
      type: "last_edited_time"
      last_edited_time: "2025-10-23T13:32:00.000Z"
    summary:
      id: "x%3AlD"
      type: "rich_text"
      rich_text: []
    Name:
      id: "title"
      type: "title"
      title:
        - type: "text"
          text:
            content: "fp8 量化的几种姿势"
            link: null
          annotations:
            bold: false
            italic: false
            strikethrough: false
            underline: false
            code: false
            color: "default"
          plain_text: "fp8 量化的几种姿势"
          href: null
  url: "https://www.notion.so/fp8-28b2875f4bfe802bacebe6b06e48c058"
  public_url: "https://polym.notion.site/fp8-28b2875f4bfe802bacebe6b06e48c058"
MANAGED_BY_NOTION_HUGO: true

---


# 背景


今年以来，在图像视频领域，开源的 AIGC 模型参数规模越来越大，例如，QwenImage 达到了 20B，Wan2.2 达到了 27B（High-Noise 和 Low-Noise 专家各占用 14B）。参数规模越大，就意味着需要更多的显存来加载模型，需要更多的算力来进行模型推理。而此时如果你想将这些 SOTA 模型运行在更加经济的消费级显卡时，就需要对模型进行量化（可以理解为压缩）。对于一张 24GB 显存的 4090 显卡而言，如果想要加载 QwenImage 20B 模型，就必须将模型权重量化到 fp8 精度。具体估算方式如下：


```python
num_params = 20 * 2^30
fp8_size = 1 byte

total_size = num_params * fp8_size = 20 * 2^30 * 1 byte = 20 GBytes
```


最近 musubi-tuner 的作者正在比较不同 fp8 量化方式对图片生成结果的影响，正好我对 ComfyUI 模型使用的 fp8_e4m3、fp8_e4m3fn、fp8_e5m2 等不同的 fp8 精度也一知半解，于是决定做一次系统的学习与整理。


# 关于精度与量化


![](https://aha.qingy.ing/api?block_id=28b2875f-4bfe-80ed-bc65-ca7c746b0ad1)


浮点精度相信大家都不陌生，只不过接触比较多可能是 float32 单精度浮点数或者 float64 双精度浮点数。简单来说，浮点数的表示分为「符号位」、「指数位」、「尾数位」三个部分，如上图所示，其中每个色块代表一个 bit。你会发现 float8 精度有两个表示方式，fp8_e4m3 和 fp8_e5m2，不同的表示意味着不同的取值范围。


而所谓的量化，其实是将数值从较大的精度范围（bf16）缩小到较小的精度范围（fp8_e4m3）；反量化则刚好相反。


另外，可能还会看到 `fp8_e4m3fn`、`fp8_e4m3fnuz` 等精度，其中 `fn` 代表没有无穷值，`uz` 代表没有负零。


# FP8 的几种量化方式


![](https://aha.qingy.ing/api?block_id=28c2875f-4bfe-80fe-a050-e131b6fe277d)


将 bf16 精度的数值量化到 fp8_e5m2 精度，有以下 3 种方式：

1. Cast-To：该方法不属于量化范畴，只是简单的数值转换。可以发现灰色部分会被直接映射到 INF 或者 -INF 上。代码验证：

	```html
	>>> v = torch.finfo(torch.bfloat16).max
	>>> v
	3.3895313892515355e+38
	>>> tv=torch.Tensor(v)
	>>> tv.to(torch.float8_e5m2)
	tensor([inf], dtype=torch.float8_e5m2)
	```

1. Tensor-wise FP8 量化：对于每个 Tensor（模型是由多个 Tensor 组成，Tensor 中包含一组参数），找出当前参数数值的最小取值范围，并将这个范围映射到 fp8 的范围内。该过程就是量化，其中映射过程会有一个缩放因子，通过缩放因子可以对参数进行反量化。
1. Block-wise FP8 量化：将每个 Tensor 按照固定 block 大小切分成多个 block，在对 block 中的参数按 Tensor-wise 的方法进行量化，区别在于每个 block 会有一个缩放因子。这个方法粒度更细，精度相对会更高。

⚠️ 图中不同精度的范围为粗略值，仅展示使用。


# Tensor-wise FP8 量化模型布局比较


![](https://aha.qingy.ing/api?block_id=28b2875f-4bfe-8020-b8e2-e4701e88442e)


在 Kijai 大神量化的 fp8_scale 模型中，可以看到每个 weight 同级新增了 scale_weight 用于记录缩放因子。


# 细粒度量化 (Fine-grained quantization)


> HuggingFace transformers 库中提供了对 block-wise fp8 量化方式的支持


![](https://aha.qingy.ing/api?block_id=28b2875f-4bfe-80fb-9ad8-cbb92ac6dc26)


# 参考资料

- 
- [https://huggingface.co/docs/transformers/en/quantization/finegrained_fp8](https://huggingface.co/docs/transformers/en/quantization/finegrained_fp8)
- [https://www.aidoczh.com/onnx/technical/float8.html](https://www.aidoczh.com/onnx/technical/float8.html)
- 
- 
- [https://developer.nvidia.com/zh-cn/blog/fp8-challenges-best-practices/](https://developer.nvidia.com/zh-cn/blog/fp8-challenges-best-practices/)
