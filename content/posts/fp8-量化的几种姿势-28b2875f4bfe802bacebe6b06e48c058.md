---
title: "fp8 量化的几种姿势"
date: "2025-10-13T12:22:00.000Z"
lastmod: "2025-10-13T14:41:00.000Z"
draft: true
featuredImage: "https://aha.qingy.ing/api?page_id=28b2875f-4bfe-802b-aceb-e6b06e48c058"
series: []
authors:
  - "Hongbo Mo"
tags:
  - "AI"
  - "PyTorch"
categories:
  - "技术"
NOTION_METADATA:
  object: "page"
  id: "28b2875f-4bfe-802b-aceb-e6b06e48c058"
  created_time: "2025-10-13T12:22:00.000Z"
  last_edited_time: "2025-10-13T14:41:00.000Z"
  created_by:
    object: "user"
    id: "1b106df3-cc7b-493e-9afa-a6a7c977ec1b"
  last_edited_by:
    object: "user"
    id: "1b106df3-cc7b-493e-9afa-a6a7c977ec1b"
  cover:
    type: "file"
    file:
      url: "https://prod-files-secure.s3.us-west-2.amazonaws.com/dc681554-1505-4cec-9\
        a8f-844b66d5dcc8/26c13cd4-5fdd-42b4-b999-932c1238eec9/dafosi.jpeg?X-Amz\
        -Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz\
        -Credential=ASIAZI2LB4667MI2KYYK%2F20251014%2Fus-west-2%2Fs3%2Faws4_req\
        uest&X-Amz-Date=20251014T012700Z&X-Amz-Expires=3600&X-Amz-Security-Toke\
        n=IQoJb3JpZ2luX2VjEKj%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLXdlc3QtMiJHM\
        EUCIQDa0XF7N%2FtF4x6fzhFiF29tMJNiPS%2BTsac%2BH42JWPvcCwIgV5cB3as08Ho1ew\
        0UNXMx0kY6s80CLXbZJDkOFMrFbn8q%2FwMIURAAGgw2Mzc0MjMxODM4MDUiDCGrZIROIFn\
        gSNHsxCrcA6tvGHNBa2CHRuUTZkLuMZXxKvIrk%2B50Bi8sF2BSzveYhLv19azenqpJ4RVI\
        YsJ8a%2F6rGXFCzbXDlXpO%2Fj7BbZllWvWUxyeodnbW0oudlZErJDav6tzwkJqTqLOZZdI\
        FKJKlqY65xwAXzaQmUVg4vpYrSqB2VheTk9hBw0tqlVnYOpiuodIXQA3aa5j0Lvrr0WZmy4\
        iRDgj9H%2FacqbGna8W2lYWvm90tIWG%2B%2BjI9ZqH1MpZVf77kSyb1AtQiyOOLBLYFHKG\
        5mTos4hwOZfF6grWwOJp0%2F3JnuoJBDe53Vm5rLh9eKTfFwFi3RbnztlxvqWBNgYwDcpcp\
        LcmnZNN7ZlRaBNttJg2clOvwT5JXF8CG1OLeJl3pp%2BQob8w4E04lQX1kmX9YOe8MgT2Oe\
        dkufZqjmTwser5cx8RkCdlLnAsmcnGdU2JT0TSvoYl4XCD2fT%2FvfrOnWde02K4fdB95y7\
        nVHUTOfT1LPLxVxNwgnCYsR5fgDsaVH43v%2BLTZrYm7Rh7v2BlnR%2F1ru5h8057BrTrDg\
        GJ4TazZyM9DqKD58nEZtdGcXmKsyQbyWaoK7nuu0mrXMxSeFRZ%2Fc3SuzMSuI%2FGsOeNw\
        1YEqQLd7fPK17h8Amf4NZi4k037grhxGMPiptscGOqUB4LLCcGe6jLG8LmVphHLz25laNro\
        CR86w1tD5Dr%2BwzKRpBfwE8JbtYleAFj282SRZfThIdaSmOnI%2FE5P80czWuyZBeRIDJV\
        %2Fv%2Bgf%2BvPf3d0m%2FwEGm7K%2BXfbbss%2F%2FwtdF8xUZ%2B7s9ilhMeQrlM5qD5Z\
        Z%2BM3LyOFJRi5x5yQZ%2Ba1X%2F%2FdU1ErUW050SwQnThBKX9TcFDh3BZz%2F4oco94PR\
        TQkbrXOswF&X-Amz-Signature=853a35f456d380cbad936513fb22591603f6887be17c\
        7334b3bd7aef60f057bd&X-Amz-SignedHeaders=host&x-amz-checksum-mode=ENABL\
        ED&x-id=GetObject"
      expiry_time: "2025-10-14T02:27:00.498Z"
  icon: null
  parent:
    type: "database_id"
    database_id: "2742875f-4bfe-8102-8a94-f918ade28f0e"
  archived: false
  in_trash: false
  is_locked: false
  properties:
    series:
      id: "B%3C%3FS"
      type: "multi_select"
      multi_select: []
    draft:
      id: "JiWU"
      type: "checkbox"
      checkbox: true
    authors:
      id: "bK%3B%5B"
      type: "people"
      people:
        - object: "user"
          id: "1b106df3-cc7b-493e-9afa-a6a7c977ec1b"
          name: "Hongbo Mo"
          avatar_url: "https://lh3.googleusercontent.com/-TqDAswHjpLU/AAAAAAAAAAI/AAAAAAA\
            ACcE/ytljzmTe0FE/photo.jpg"
          type: "person"
          person:
            email: "zjutpolym@gmail.com"
    custom-front-matter:
      id: "c~kA"
      type: "rich_text"
      rich_text: []
    tags:
      id: "jw%7CC"
      type: "multi_select"
      multi_select:
        - id: "40547cf7-b44a-442e-bda4-0c8227541945"
          name: "AI"
          color: "purple"
        - id: "683854ba-d6f3-4e29-a95e-585859c16642"
          name: "PyTorch"
          color: "orange"
    categories:
      id: "nbY%3F"
      type: "multi_select"
      multi_select:
        - id: "3e64a788-1d3d-460d-ad3a-18dc5cbc48e5"
          name: "技术"
          color: "brown"
    Last edited time:
      id: "vbGE"
      type: "last_edited_time"
      last_edited_time: "2025-10-13T14:41:00.000Z"
    summary:
      id: "x%3AlD"
      type: "rich_text"
      rich_text: []
    Name:
      id: "title"
      type: "title"
      title:
        - type: "text"
          text:
            content: "fp8 量化的几种姿势"
            link: null
          annotations:
            bold: false
            italic: false
            strikethrough: false
            underline: false
            code: false
            color: "default"
          plain_text: "fp8 量化的几种姿势"
          href: null
  url: "https://www.notion.so/fp8-28b2875f4bfe802bacebe6b06e48c058"
  public_url: "https://polym.notion.site/fp8-28b2875f4bfe802bacebe6b06e48c058"
MANAGED_BY_NOTION_HUGO: true

---


# 背景


今年以来，在图像视频领域，开源的 AIGC 模型参数规模越来越大，例如，QwenImage 达到了 20B，Wan2.2 达到了 27B（High-Noise 和 Low-Noise 专家各占用 14B）。参数规模越大，就意味着需要更多的显存来加载模型，需要更多的算力来进行模型推理。而此时如果你想将这些 SOTA 模型运行在更加经济的消费级显卡时，就需要对模型进行量化（可以理解为压缩）。对于一张 24GB 显存的 4090 显卡而言，如果想要加载 QwenImage 模型，就必须将模型权重量化到 fp8 精度。如果采用 fp8 精度，模型显存占用粗略估算如下，可以放到 24GB 显存中：


```makefile
num_params = 20 * 2^30
fp8_size = 1 byte

total_size = num_params * fp8_size = 20 * 2^30 * 1 byte = 20 GBytes
```


正好最近发现模型训练工具 musubi-tuner 作者正在比较不同 fp8 量化方式对图片生成结果的影响，以及对 ComfyUI 模型精度 fp8_e4m3、fp8_e5m2、fp8_e3m2_fast 的一知半解，决定做一次系统的学习与整理。


# 精度与量化


![](https://aha.qingy.ing/api?block_id=28b2875f-4bfe-80ed-bc65-ca7c746b0ad1)


浮点精度相信大家都不陌生，只不过接触比较多可能是 float32 单精度浮点数或者 float64 双精度浮点数。简单来说，浮点数的表示分为「符号位」、「指数位」、「尾数位」，如上图所示，其中每个色块代表一个 bit。你会发现 float8 精度有两个表示方式，fp8_e4m3 和 fp8_e5m2，不同的表示意味着不同的取值范围，fp8_e5m2 范围为 [-2^15, 2^15]，而 fp8_e4m3 只有 [-2^7, 2^7]。


而所谓的量化，其实是将数值从较大的精度范围（bf16）缩小到较小的精度范围（fp8_e4m3）；反量化则刚好相反。


# FP8 的几种量化方式


![](https://aha.qingy.ing/api?block_id=28b2875f-4bfe-8045-81fc-ea743e8b7cf7)


将 bf16 精度的数值量化到 fp8_e5m2 精度，有以下 3 种方式：

1. Cast-To：该方法不属于量化范畴，只是简单的数值转换。可以发现灰色部分会被直接映射到最小或最大值上。
1. Tensor-wise FP8 量化：对于每个 Tensor（模型是由多个 Tensor 组成，Tensor 中包含一组参数），找出当前参数数值的最小取值范围，并将这个范围映射到 fp8 的范围内。该过程就是量化，其中映射过程会有一个缩放因子，通过缩放因子可以对参数进行反量化。
1. Block-wise FP8 量化：将每个 Tensor 按照固定 block 大小切分成多个 block，在对 block 中的参数按 Tensor-wise 的方法进行量化，区别在于每个 block 会有一个缩放因子。这个方法粒度更细，精度相对会更高。

# Tensor-wise FP8 量化模型布局比较


![](https://aha.qingy.ing/api?block_id=28b2875f-4bfe-8020-b8e2-e4701e88442e)


# 细粒度量化 (Fine-grained quantization)


> HuggingFace transformers 库中提供了对 block-wise fp8 量化方式的支持


![](https://aha.qingy.ing/api?block_id=28b2875f-4bfe-80fb-9ad8-cbb92ac6dc26)


# 参考资料

- 
- [https://huggingface.co/docs/transformers/en/quantization/finegrained_fp8](https://huggingface.co/docs/transformers/en/quantization/finegrained_fp8)
