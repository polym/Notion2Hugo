---
title: "ComfyUI 模型加载分析 & 自定义量化算子"
date: "2025-10-18T01:41:00.000Z"
lastmod: "2025-10-18T07:05:00.000Z"
draft: true
featuredImage: "https://aha.qingy.ing/api?page_id=2902875f-4bfe-8062-82e2-f68a48365724"
series: []
authors:
  - "Hongbo Mo"
tags:
  - "Comfy"
categories:
  - "技术"
NOTION_METADATA:
  object: "page"
  id: "2902875f-4bfe-8062-82e2-f68a48365724"
  created_time: "2025-10-18T01:41:00.000Z"
  last_edited_time: "2025-10-18T07:05:00.000Z"
  created_by:
    object: "user"
    id: "1b106df3-cc7b-493e-9afa-a6a7c977ec1b"
  last_edited_by:
    object: "user"
    id: "1b106df3-cc7b-493e-9afa-a6a7c977ec1b"
  cover:
    type: "file"
    file:
      url: "https://prod-files-secure.s3.us-west-2.amazonaws.com/dc681554-1505-4cec-9\
        a8f-844b66d5dcc8/8cc4b7eb-1b27-4fa3-b6d0-b69b55708982/DSCF9322_preview.\
        jpeg?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAY\
        LOAD&X-Amz-Credential=ASIAZI2LB4666LTTKLBG%2F20251019%2Fus-west-2%2Fs3%\
        2Faws4_request&X-Amz-Date=20251019T014607Z&X-Amz-Expires=3600&X-Amz-Sec\
        urity-Token=IQoJb3JpZ2luX2VjECIaCXVzLXdlc3QtMiJGMEQCIC5XfbCsrN4PGtQLlyG\
        TvNRkyEKHGfwAbs%2FOckuJSkCsAiAL5CwUUgFV%2Fc1IR3WF9pEBuJhI6Nha763Fo3kROL\
        PfKCqIBAjK%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAAaDDYzNzQyMzE4MzgwNSIM84llh\
        CiE3UwcBGZ7KtwDhPRARSFzJiiJnbdVNX%2FnB1bnLchxqaYoE6Pp%2F%2BPhK1mWl7zAhK\
        4OEhXMfq99tn7PQq0hKjKQXTc9rCG8Nqr7lF3o7E2CmA2M4bJpN03qT5WOGG06cmTa5yl0P\
        0qvJNYH%2FZJm8rUs1gRde9ZMAOsMIjHwMqHtV%2Fsq07Im9o1A3ht0eTRTJeXMGJOeL%2F\
        J9%2BViVyj9PjRLcvAw3oGU%2F9A%2FrKUqhQLN3eVAUmidbRx%2BP9xC%2Bpi93zy1iS98\
        2Y1o5DHi%2BgUIiKgVxCT8rZTcZVtPEIH5sw6tYObtrp8PaJa%2FO8Ka6y%2BdgtnOjNHDZ\
        VOU8WMX3XMAsJQhXgK8s5DUAFdemNc5KtPherZm5l%2F9kKg5ulDhxLTYhfI5KjOu%2F%2F\
        l6e5oAgaBk8Q3EqPocRG9M03EMpdQuewMcHzyGIoCaq6rTdkMuILKF7w%2BPD8Vd3WOPHw8\
        c8OpaVCUhKFjdwja1e%2FdLwSjpNTH5CT7qhHR%2BD5qsShJU0riWrBw994N6GzjoH6t5ei\
        ANoqTszIjPmH4J5POB%2FsNycT5NLfIiTQmcqQYeXJlBMYPvcgcHJxU1PTx65RshKMd%2Bj\
        8qvBOyl0HSK%2Fe5TYKauLQLuetNv%2BoUejbVzFsxerQskJ3WkPM%2FW%2BtNswjvvQxwY\
        6pgG2YuCZzKn450hFMogW8xfMxFJtRNocgtJb4pCZwGzBrZj1nkqw20vJLlTg2BgMaltT1U\
        IZZuG7a8VQAvCSbF083uZEziWwI69%2B16uWw2fWqjwdt8SrpFCuqGTXi0RLnuz0ehTfZt%\
        2FPyQ8CPbg9SIxUWehF0C9Q5do5RYL%2FKCcbqMCPzbFEgGRXD2X%2BM0F59n2xBzBIF4c3\
        cwO1DFCYTfZ%2Bdm%2FfB0S3&X-Amz-Signature=805bcb92994fe2000d5f908d95f537\
        1ba3a2e9f09fe89f3ed0404bc3dda2c5a9&X-Amz-SignedHeaders=host&x-amz-check\
        sum-mode=ENABLED&x-id=GetObject"
      expiry_time: "2025-10-19T02:46:07.964Z"
  icon: null
  parent:
    type: "database_id"
    database_id: "2742875f-4bfe-8102-8a94-f918ade28f0e"
  archived: false
  in_trash: false
  is_locked: false
  properties:
    series:
      id: "B%3C%3FS"
      type: "multi_select"
      multi_select: []
    draft:
      id: "JiWU"
      type: "checkbox"
      checkbox: true
    authors:
      id: "bK%3B%5B"
      type: "people"
      people:
        - object: "user"
          id: "1b106df3-cc7b-493e-9afa-a6a7c977ec1b"
          name: "Hongbo Mo"
          avatar_url: "https://lh3.googleusercontent.com/-TqDAswHjpLU/AAAAAAAAAAI/AAAAAAA\
            ACcE/ytljzmTe0FE/photo.jpg"
          type: "person"
          person:
            email: "zjutpolym@gmail.com"
    custom-front-matter:
      id: "c~kA"
      type: "rich_text"
      rich_text: []
    tags:
      id: "jw%7CC"
      type: "multi_select"
      multi_select:
        - id: "05fff7c0-97e9-432d-81fc-c4b753c4d418"
          name: "Comfy"
          color: "blue"
    categories:
      id: "nbY%3F"
      type: "multi_select"
      multi_select:
        - id: "3e64a788-1d3d-460d-ad3a-18dc5cbc48e5"
          name: "技术"
          color: "brown"
    Last edited time:
      id: "vbGE"
      type: "last_edited_time"
      last_edited_time: "2025-10-18T07:05:00.000Z"
    summary:
      id: "x%3AlD"
      type: "rich_text"
      rich_text: []
    Name:
      id: "title"
      type: "title"
      title:
        - type: "text"
          text:
            content: "ComfyUI 模型加载分析 & 自定义量化算子"
            link: null
          annotations:
            bold: false
            italic: false
            strikethrough: false
            underline: false
            code: false
            color: "default"
          plain_text: "ComfyUI 模型加载分析 & 自定义量化算子"
          href: null
  url: "https://www.notion.so/ComfyUI-2902875f4bfe806282e2f68a48365724"
  public_url: "https://polym.notion.site/ComfyUI-2902875f4bfe806282e2f68a48365724"
MANAGED_BY_NOTION_HUGO: true

---


# 背景


前文提到 musubi-tunner 作者自己实现了 block-wise fp8 scaling，并且代码非常精简，但是 ComfyUI 还没有对此进行支持。而在 [https://github.com/kohya-ss/musubi-tuner/issues/634](https://github.com/kohya-ss/musubi-tuner/issues/634) 中也提到了想要使用 ComfyUI 来体验 block-wise fp8 scaling。


ComfyUI 接触也有一段时间，决定来手搓一个插件。在搓插件之前，需要先理解 ComfyUI 当前加载模型的逻辑。在 ComfyUI 中，官方提供了加载 diffusion 模型的节点 UNetLoader、加载 LoRA 模型的节点 LoraLoader、以及运行模型的节点 KSampler。


这里还有一点提下，VSCode + 单步调试 + Github Copilot 简直是查看 Python 代码的绝佳组合，非常高效。


# 模型加载过程图


三个核心节点：

1. UNETLoader：从硬盘读取模型文件，根据文件内容判断模型类型，并生成模型对象，最终加载模型到 cpu 上，得到 ModelPatcher
1. LoraLoader：从硬盘读取模型文件，并将模型数据保存在 ModelPatcher 的 object_patches 字段中
1. KSampler：将 ModelPatcher 中存放的 lora 权重合并到 model 上，随后加载到 GPU 上，最后运行推理

![](https://aha.qingy.ing/api?block_id=2902875f-4bfe-80ff-a18e-d2fd853f9c74)


# 自定义算子，加载 block wise scaled 模型


> 场景一：参考 kijai 大神的做法，先使用 block wise scaling 方法将 QwenImage 量化后导出模型文件，然后在使用 ComfyUI 时加载量化后的模型。


为满足这个场景，可以按以下思路来做：

- 劫持 `__init__` 方法，用于设置模块的 dtype，例如，fp8_e4m3，后续在 load_state_dict 时会将具体的数值 cast_to 到该 dtype 上
- 劫持 `reset_parameters` 方法，用于为模块新增参数。在 block wise scaling 场景下，模型中会多一个 scale_weight 字段，该字段在原始模型结构中不存在。因此，需要通过 reset_parameters 新增 scale_weight 参数。
- 劫持 `forward` 方法，用于接入自定义 foward 逻辑。在 block wise scaling 场景下，需要先将加载的权重通过 scale_weight 反量化成 bf16，然后执行 forward 运算。

具体实现如下：[https://github.com/polym/ComfyUI-musubi/blob/main/modules/comfy_ops.py](https://github.com/polym/ComfyUI-musubi/blob/main/modules/comfy_ops.py)


# 如何在线量化？


> 场景二：将 LoRA 权重加载到 QwenImage 模型后再进行量化。


针对该场景，ComfyUI 原生 UNETLoader 节点，在完成模型加载后就无法再次进行量化，因此无法满足需求。我们需要自己来实现模型加载、LoRA 权重合并以及量化等过程，然后以 ModelPatcher 的形式返回。这里遇到一个问题，需要正确使用 set_inference_dtype 设置 dtype。具体细节不做展开，可以查看 [https://github.com/polym/ComfyUI-musubi/blob/main/modules/nodes.py#L68](https://github.com/polym/ComfyUI-musubi/blob/main/modules/nodes.py#L68)


# 其他思考

1. 为什么 LoadLora 时没有立即将 LoRA 权重合并到模型上，而是做了保存？

	初步想法💡：为了能够有效的复用加载后的 diffusion model，支持在线合并/卸载 LoRA 权重。

1. 如果模型的部分权重被 offload 到 cpu 上，在模型推理时，如何保证运算的数据同时在 cpu 或者 gpu 上？

	首先，Comfy 默认会劫持所有常见的 torch.nn.Module，在 forward 函数中，通过 cast_weight_bias 方法，将 weight 和 bias 的临时变量转成 input 的 dtype 和 device。因此，可以保证所有的运算都会在同一个设备上执行。但是，我们在实际使用 ComfyUI 时还是可能遇到 **Expected all tensors to be on the same device 的报错，这个需要具体问题具体分析。**

