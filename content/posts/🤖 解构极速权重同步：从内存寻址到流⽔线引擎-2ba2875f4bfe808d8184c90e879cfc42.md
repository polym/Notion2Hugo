---
title: "🤖 解构极速权重同步：从内存寻址到流⽔线引擎"
date: "2025-11-29T03:18:00.000Z"
lastmod: "2025-12-01T13:38:00.000Z"
draft: false
featuredImage: "https://aha.qingy.ing/api?page_id=2ba2875f-4bfe-808d-8184-c90e879cfc42"
series: []
authors:
  - "Hongbo Mo"
tags:
  - "AI"
  - "推理"
categories: []
NOTION_METADATA:
  object: "page"
  id: "2ba2875f-4bfe-808d-8184-c90e879cfc42"
  created_time: "2025-11-29T03:18:00.000Z"
  last_edited_time: "2025-12-01T13:38:00.000Z"
  created_by:
    object: "user"
    id: "1b106df3-cc7b-493e-9afa-a6a7c977ec1b"
  last_edited_by:
    object: "user"
    id: "1b106df3-cc7b-493e-9afa-a6a7c977ec1b"
  cover:
    type: "file"
    file:
      url: "https://prod-files-secure.s3.us-west-2.amazonaws.com/dc681554-1505-4cec-9\
        a8f-844b66d5dcc8/d21d814f-6f44-413d-b097-535020e3c4ae/0ED35B35-2B15-43F\
        E-904C-85D12FA25F28.jpg?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-\
        Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=ASIAZI2LB4667PIULNO3%2F2025120\
        2%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Date=20251202T014450Z&X-Amz-Exp\
        ires=3600&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEEAaCXVzLXdlc3QtMiJGMEQC\
        IGMqqiEMxtuNJ3GyzYP%2BCJKAolUIK%2Fa3hJmN5kmfML8AAiByx2AfYwItfZ5pM%2Bf3v\
        13eg8oYgBjik%2FwMqhtCfDukxyr%2FAwgJEAAaDDYzNzQyMzE4MzgwNSIMyZ135hwm99TD\
        OcX4KtwDHK2rIQ3U9WQpmG1FbWyBw7Fn9fQNn6cUurGcyqaTzkRwI%2FaptRRxlMZ7dbeHN\
        ZlILxQqa4BD6KDB7XnH953VwobHZNuGj8eIBAA%2BEQLYqyWrgCug2Z9TDB81lZctDj%2B6\
        ga2XadQPakfSE50fn%2F87HA3KyZI8FX3UEut4LK8G1iSAXJCn4q22FfHagkV6ZqYi4Rpz4\
        MAls032QlXfaS3nxmWzHy7sg8DPiIuMv6%2FklbPw4bIxfC7o4YMSkQCd%2B8oQLy7shHlS\
        JRfATXd3zdf3sLgD36XY9sZqnYM6ZEwFuzg9QHRp%2FC3Wzoq9C1raoKLu2Xiz%2FFvkS74\
        JQk%2BnOvyM9VtPHP7WLT52bwcCmJnaytr%2Fm4yghrP2SF%2Fgko1O0Mv3HVY36uZverES\
        pO0y7KWhDaDza8Hbo0b9L2Kq%2BsF0Yzp7LUhAsk3V%2FTjz7%2F5GqN2h5S%2Fn3loDW7p\
        K36Aub73pbFrOO4Jp8Mt1bOq3HbOvOFXa4IVVcISgx3ftHl8qjKtTBBv6Y7iajH27%2BRID\
        3CTjAQhPj4bb5CwrbW7W5yEIDwWOP1L9vc5LhrrKwnv7SPFf%2B6TMIXRyJNtDCA%2B4K%2\
        FVW%2FZVnc0DBd%2Bu4F0bSi0IxoH1asMTZ4xJcy2je1BIw4964yQY6pgGCc1RmJzz7pB6e\
        HAs4p1t%2Fs%2BqZoPqlcUDoBOpobPFIlnri7oViN4apB35ELCr92nqKXGvT0rdEo1Rlds2\
        lyQICIhljOAUGTLg0%2FBrpoHDLGXpNmqc4bo0ScjytrrUGbuxD18W%2FFaMMHISoURP8fq\
        XuMbCHpVYD6fD0%2BiIpZS5FE3PISx1XN10AhIR4oHlYoyQ6zNp7HpjmWeqrDhpXAfxLZxs\
        AaXa7&X-Amz-Signature=a8a81d847163ef77b5e3a47ac1c70014e91ff7b0a1de6f00b\
        5f327f5409f73a8&X-Amz-SignedHeaders=host&x-amz-checksum-mode=ENABLED&x-\
        id=GetObject"
      expiry_time: "2025-12-02T02:44:50.311Z"
  icon: null
  parent:
    type: "database_id"
    database_id: "2742875f-4bfe-8102-8a94-f918ade28f0e"
  archived: false
  in_trash: false
  is_locked: false
  properties:
    series:
      id: "B%3C%3FS"
      type: "multi_select"
      multi_select: []
    draft:
      id: "JiWU"
      type: "checkbox"
      checkbox: false
    authors:
      id: "bK%3B%5B"
      type: "people"
      people:
        - object: "user"
          id: "1b106df3-cc7b-493e-9afa-a6a7c977ec1b"
          name: "Hongbo Mo"
          avatar_url: "https://lh3.googleusercontent.com/-TqDAswHjpLU/AAAAAAAAAAI/AAAAAAA\
            ACcE/ytljzmTe0FE/photo.jpg"
          type: "person"
          person:
            email: "zjutpolym@gmail.com"
    custom-front-matter:
      id: "c~kA"
      type: "rich_text"
      rich_text: []
    tags:
      id: "jw%7CC"
      type: "multi_select"
      multi_select:
        - id: "40547cf7-b44a-442e-bda4-0c8227541945"
          name: "AI"
          color: "purple"
        - id: "e89da956-37fb-4695-a673-8f4def74c09e"
          name: "推理"
          color: "pink"
    categories:
      id: "nbY%3F"
      type: "multi_select"
      multi_select: []
    Last edited time:
      id: "vbGE"
      type: "last_edited_time"
      last_edited_time: "2025-12-01T13:38:00.000Z"
    summary:
      id: "x%3AlD"
      type: "rich_text"
      rich_text: []
    Name:
      id: "title"
      type: "title"
      title:
        - type: "text"
          text:
            content: "🤖 解构极速权重同步：从内存寻址到流⽔线引擎"
            link: null
          annotations:
            bold: false
            italic: false
            strikethrough: false
            underline: false
            code: false
            color: "default"
          plain_text: "🤖 解构极速权重同步：从内存寻址到流⽔线引擎"
          href: null
  url: "https://www.notion.so/2ba2875f4bfe808d8184c90e879cfc42"
  public_url: "https://polym.notion.site/2ba2875f4bfe808d8184c90e879cfc42"
MANAGED_BY_NOTION_HUGO: true

---


# 背景


在 KCD Hangzhou 的活动中有幸跟百炼的于文渊大佬做了交流，得知在模型同步可以考虑 p2p 分发的方式。于是做了一个简单的调研，发现 Kimi 开源的推理引擎 Mooncake 也提供了类似的方法，就花时间阅读了下源码，共涉及 [Mooncake](https://github.com/kvcache-ai/Mooncake) 和 [checkpoint-engine](https://github.com/MoonshotAI/checkpoint-engine) 两个项目。 实话说，本人对 AI 硬件与内核联动相关领域并不熟悉，因此在阅读源码过程中，有很多专业性的技术了解甚少，理解起来十分吃力。好在如今有 Copilot 协助，才得以完成代码阅读。在这个过程中也发现一个很有意思的阅读源码的方法：

1. 在 VSCode 中让 Github Copilot 进行辅助阅读源码，针对不明白的点，及时提问
1. 等所有细节都整理清楚后，将与 Copilot 的聊天内容导入到 NotebookLM 中
1. 在 NotebookLM 中，再次对内容进行梳理，NotebookLM 也会主动引导提问
1. 对 NotebookLM 每轮返回的结果进行评估，如果符合预期则保存为 note
1. 在 NotebookLM 中，将所有保存的 note 作为 source，然后通过「Slide Deck」生成 Slide

接下来，我将使用生成的 Slide，来分析大模型 p2p 分发的逻辑。


# 核⼼挑战：⼤模型时代下的权重更新瓶颈


![](https://aha.qingy.ing/api?block_id=2ba2875f-4bfe-809a-8674-da789db0f45f)


## 优化一：提供硬件直达，消除中介


通过「内存注册」，提供硬件可直接操作的物理地址


![](https://aha.qingy.ing/api?block_id=2ba2875f-4bfe-80e4-948e-dbb326be409b)


![](https://aha.qingy.ing/api?block_id=2ba2875f-4bfe-801a-b2d2-e7ed16957027)


# 优化二：零拷贝与内核旁路，告别开销


利用 RDMA 和 NVLink & CUDA IPC 技术，实现内存和硬件之间的直接流动，完全绕过 CPU 和操作系统内核。


![](https://aha.qingy.ing/api?block_id=2ba2875f-4bfe-801d-aa02-c7e2f85d8688)


![](https://aha.qingy.ing/api?block_id=2ba2875f-4bfe-804b-a81f-c2ffd97dbceb)


# 优化三：利用 P2P 以及流水异步化机制，压榨并行


> 这里需要补充一点，在 checkpoint-engine 中 P2P 只在 h2d 阶段获取原始权重时才会用到，其余权重同步逻辑均由 NCCL 库来实现。


### 单 GPU 视角


![](https://aha.qingy.ing/api?block_id=2ba2875f-4bfe-8074-a368-ec8576731a57)


![](https://aha.qingy.ing/api?block_id=2ba2875f-4bfe-80e4-9094-eab3abcf353f)


### 多 GPU 视角


![](https://aha.qingy.ing/api?block_id=2ba2875f-4bfe-8096-9865-d39a40d7d5a2)


# 总体架构回顾


![](https://aha.qingy.ing/api?block_id=2ba2875f-4bfe-803d-9feb-c1d09ef15d85)


# P2P 分发 & vLLM 更新权重


![](https://aha.qingy.ing/api?block_id=2bc2875f-4bfe-80e3-926e-e76235753d66)


![](https://aha.qingy.ing/api?block_id=2bc2875f-4bfe-8088-942c-c9f2ad04a87c)


# 总结 & 思考


Mooncake 项目中的 TransferEngine 提供了内存注册以及卡间传输的多个方法，Checkpoint engine 在 TE 之上增加了 P2P Store 和权重 bucket pipeline 同步机制，加速模型分发速度。


此架构下有几个优点：

1. 权重按 bucket 细分后，可以充分利用 PCIE、RDMA 性能，减少硬件闲置
1. 巧妙的利用 Ping/Pong buffer 来实现读写分离，保证高效并行

缺点：

1. 直接使用 NCCL 库来做同步，而不是 TransferEngine 的 P2P 来做，蛮可惜的，无法确定 TransferEngine P2P  的性能
1. NCCL 同步需要保证所有 GPU 都完成操作，一旦有一个没有完成，则所有进程均会卡住

最后，能否用到 ComfyUI 场景上？目前来看并不合适，checkpoint engine 面向的场景是 Kimi 模型从训练集群如何快速更新到推理集群的问题，在这个场景下可以保证权重文件一定可以在 P2P store 中找到，而 ComfyUI 场景中，模型替换非常频繁，很大程度上无法在 P2P 网络里找到对应的权重，最后还是要回退到从磁盘读取模型权重。再说说类似百炼这类 MaaS 场景，这种场景下是合适的，模型更替频率不高，但是一旦发生更替，速度需要越快越好，以减少服务不可用时间。

